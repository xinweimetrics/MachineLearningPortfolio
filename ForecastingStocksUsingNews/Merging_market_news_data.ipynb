{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Market and News Data\n",
    "\n",
    "This notebook merges stock market data from Intrinio, and news data from Thomson Reuters. The author thanks Robert Lutostanski, for getting access to the data.  \n",
    "\n",
    "Author: Xin Wei (weixin0127@gmail.com), Indiana University Bloomington  \n",
    "Version: 2019/12/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from pytz import UTC, timezone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Display options\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data... This may take a few minutes.\n",
      "Importing data: done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing data... This may take a few minutes.\")\n",
    "market_df = pd.read_csv(\"../Data/market_train_df.csv\")\n",
    "news_df = pd.read_csv(\"../Data/news_train_df.csv\")\n",
    "print(\"Importing data: done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>assetCode</th>\n",
       "      <th>assetName</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>returnsClosePrevRaw1</th>\n",
       "      <th>returnsOpenPrevRaw1</th>\n",
       "      <th>returnsClosePrevMktres1</th>\n",
       "      <th>returnsOpenPrevMktres1</th>\n",
       "      <th>returnsClosePrevRaw10</th>\n",
       "      <th>returnsOpenPrevRaw10</th>\n",
       "      <th>returnsClosePrevMktres10</th>\n",
       "      <th>returnsOpenPrevMktres10</th>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "      <th>universe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>A.N</td>\n",
       "      <td>Agilent Technologies Inc</td>\n",
       "      <td>2606900.0</td>\n",
       "      <td>32.19</td>\n",
       "      <td>32.17</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001860</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034672</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>AAI.N</td>\n",
       "      <td>AirTran Holdings Inc</td>\n",
       "      <td>2051600.0</td>\n",
       "      <td>11.12</td>\n",
       "      <td>11.08</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.078708</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>AAP.N</td>\n",
       "      <td>Advance Auto Parts Inc</td>\n",
       "      <td>1164800.0</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.99</td>\n",
       "      <td>-0.011594</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>23747329.0</td>\n",
       "      <td>84.74</td>\n",
       "      <td>86.23</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.048613</td>\n",
       "      <td>-0.037182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007425</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>ABB.N</td>\n",
       "      <td>ABB Ltd</td>\n",
       "      <td>1208600.0</td>\n",
       "      <td>18.02</td>\n",
       "      <td>18.01</td>\n",
       "      <td>0.011791</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time assetCode                 assetName      volume  \\\n",
       "0  2007-02-01 22:00:00+00:00       A.N  Agilent Technologies Inc   2606900.0   \n",
       "1  2007-02-01 22:00:00+00:00     AAI.N      AirTran Holdings Inc   2051600.0   \n",
       "2  2007-02-01 22:00:00+00:00     AAP.N    Advance Auto Parts Inc   1164800.0   \n",
       "3  2007-02-01 22:00:00+00:00    AAPL.O                 Apple Inc  23747329.0   \n",
       "4  2007-02-01 22:00:00+00:00     ABB.N                   ABB Ltd   1208600.0   \n",
       "\n",
       "   close   open  returnsClosePrevRaw1  returnsOpenPrevRaw1  \\\n",
       "0  32.19  32.17              0.005938             0.005312   \n",
       "1  11.12  11.08              0.004517            -0.007168   \n",
       "2  37.51  37.99             -0.011594             0.025648   \n",
       "3  84.74  86.23             -0.011548             0.016324   \n",
       "4  18.02  18.01              0.011791             0.025043   \n",
       "\n",
       "   returnsClosePrevMktres1  returnsOpenPrevMktres1  returnsClosePrevRaw10  \\\n",
       "0                      NaN                     NaN              -0.001860   \n",
       "1                      NaN                     NaN              -0.078708   \n",
       "2                      NaN                     NaN               0.014332   \n",
       "3                      NaN                     NaN              -0.048613   \n",
       "4                      NaN                     NaN               0.012929   \n",
       "\n",
       "   returnsOpenPrevRaw10  returnsClosePrevMktres10  returnsOpenPrevMktres10  \\\n",
       "0              0.000622                       NaN                      NaN   \n",
       "1             -0.088066                       NaN                      NaN   \n",
       "2              0.045405                       NaN                      NaN   \n",
       "3             -0.037182                       NaN                      NaN   \n",
       "4              0.020397                       NaN                      NaN   \n",
       "\n",
       "   returnsOpenNextMktres10  universe  \n",
       "0                 0.034672       1.0  \n",
       "1                 0.027803       0.0  \n",
       "2                 0.024433       1.0  \n",
       "3                -0.007425       1.0  \n",
       "4                -0.017994       1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sourceTimestamp</th>\n",
       "      <th>firstCreated</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>headline</th>\n",
       "      <th>urgency</th>\n",
       "      <th>takeSequence</th>\n",
       "      <th>provider</th>\n",
       "      <th>subjects</th>\n",
       "      <th>audiences</th>\n",
       "      <th>bodySize</th>\n",
       "      <th>companyCount</th>\n",
       "      <th>headlineTag</th>\n",
       "      <th>marketCommentary</th>\n",
       "      <th>sentenceCount</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>assetCodes</th>\n",
       "      <th>assetName</th>\n",
       "      <th>firstMentionSentence</th>\n",
       "      <th>relevance</th>\n",
       "      <th>sentimentClass</th>\n",
       "      <th>sentimentNegative</th>\n",
       "      <th>sentimentNeutral</th>\n",
       "      <th>sentimentPositive</th>\n",
       "      <th>sentimentWordCount</th>\n",
       "      <th>noveltyCount12H</th>\n",
       "      <th>noveltyCount24H</th>\n",
       "      <th>noveltyCount3D</th>\n",
       "      <th>noveltyCount5D</th>\n",
       "      <th>noveltyCount7D</th>\n",
       "      <th>volumeCounts12H</th>\n",
       "      <th>volumeCounts24H</th>\n",
       "      <th>volumeCounts3D</th>\n",
       "      <th>volumeCounts5D</th>\n",
       "      <th>volumeCounts7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>e58c6279551b85cf</td>\n",
       "      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'EMRG', 'RTRS', 'CRU', 'ENR', 'ASIA', 'LEN', ...</td>\n",
       "      <td>{'Z', 'O', 'OIL'}</td>\n",
       "      <td>1438</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>275</td>\n",
       "      <td>{'0857.HK', 'PTR.N', '0857.F', '0857.DE'}</td>\n",
       "      <td>PetroChina Co Ltd</td>\n",
       "      <td>6</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.500739</td>\n",
       "      <td>0.419327</td>\n",
       "      <td>0.079934</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01 07:03:35+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>5a31c4327427f63f</td>\n",
       "      <td>FEATURE-In kidnapping, finesse works best</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'CO', 'HT', 'LIF', 'LATAM', 'RTRS', 'MX', 'AS...</td>\n",
       "      <td>{'ESN', 'RNP', 'G', 'E', 'U', 'PCO', 'PCU', 'M...</td>\n",
       "      <td>4413</td>\n",
       "      <td>1</td>\n",
       "      <td>FEATURE</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>907</td>\n",
       "      <td>{'STA.N'}</td>\n",
       "      <td>Travelers Companies Inc</td>\n",
       "      <td>8</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.600082</td>\n",
       "      <td>0.345853</td>\n",
       "      <td>0.054064</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>1cefd27a40fabdfe</td>\n",
       "      <td>PRESS DIGEST - Wall Street Journal - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'BG', 'TH', 'RET', 'RTRS', 'ID', 'RO', 'ENR',...</td>\n",
       "      <td>{'M', 'RNP', 'D', 'PTD', 'E', 'U', 'T', 'PMF',...</td>\n",
       "      <td>2108</td>\n",
       "      <td>2</td>\n",
       "      <td>PRESS DIGEST</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>388</td>\n",
       "      <td>{'WMT.N', 'WMT.DE'}</td>\n",
       "      <td>Wal-Mart Stores Inc</td>\n",
       "      <td>14</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.450049</td>\n",
       "      <td>0.295671</td>\n",
       "      <td>0.254280</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'LEI', 'INS', 'RTRS', 'USC', 'WWW', 'FUND', '...</td>\n",
       "      <td>{'M', 'RNP', 'D', 'PTD', 'E', 'U', 'T', 'PMF',...</td>\n",
       "      <td>1776</td>\n",
       "      <td>6</td>\n",
       "      <td>PRESS DIGEST</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>325</td>\n",
       "      <td>{'GOOG.O', 'GOOG.OQ', 'GOOGa.DE'}</td>\n",
       "      <td>Google Inc</td>\n",
       "      <td>13</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.162715</td>\n",
       "      <td>0.084368</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'LEI', 'INS', 'RTRS', 'USC', 'WWW', 'FUND', '...</td>\n",
       "      <td>{'M', 'RNP', 'D', 'PTD', 'E', 'U', 'T', 'PMF',...</td>\n",
       "      <td>1776</td>\n",
       "      <td>6</td>\n",
       "      <td>PRESS DIGEST</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>325</td>\n",
       "      <td>{'XMSR.O'}</td>\n",
       "      <td>XM Satellite Radio Holdings Inc</td>\n",
       "      <td>11</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.699274</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>0.091367</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time            sourceTimestamp  \\\n",
       "0  2007-01-01 04:29:32+00:00  2007-01-01 04:29:32+00:00   \n",
       "1  2007-01-01 07:03:35+00:00  2007-01-01 07:03:34+00:00   \n",
       "2  2007-01-01 11:29:56+00:00  2007-01-01 11:29:56+00:00   \n",
       "3  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "4  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "\n",
       "                firstCreated          sourceId  \\\n",
       "0  2007-01-01 04:29:32+00:00  e58c6279551b85cf   \n",
       "1  2007-01-01 07:03:34+00:00  5a31c4327427f63f   \n",
       "2  2007-01-01 11:29:56+00:00  1cefd27a40fabdfe   \n",
       "3  2007-01-01 12:08:37+00:00  23768af19dc69992   \n",
       "4  2007-01-01 12:08:37+00:00  23768af19dc69992   \n",
       "\n",
       "                                            headline  urgency  takeSequence  \\\n",
       "0  China's Daqing pumps 43.41 mln tonnes of oil i...        3             1   \n",
       "1          FEATURE-In kidnapping, finesse works best        3             1   \n",
       "2         PRESS DIGEST - Wall Street Journal - Jan 1        3             1   \n",
       "3              PRESS DIGEST - New York Times - Jan 1        3             1   \n",
       "4              PRESS DIGEST - New York Times - Jan 1        3             1   \n",
       "\n",
       "  provider                                           subjects  \\\n",
       "0     RTRS  {'EMRG', 'RTRS', 'CRU', 'ENR', 'ASIA', 'LEN', ...   \n",
       "1     RTRS  {'CO', 'HT', 'LIF', 'LATAM', 'RTRS', 'MX', 'AS...   \n",
       "2     RTRS  {'BG', 'TH', 'RET', 'RTRS', 'ID', 'RO', 'ENR',...   \n",
       "3     RTRS  {'LEI', 'INS', 'RTRS', 'USC', 'WWW', 'FUND', '...   \n",
       "4     RTRS  {'LEI', 'INS', 'RTRS', 'USC', 'WWW', 'FUND', '...   \n",
       "\n",
       "                                           audiences  bodySize  companyCount  \\\n",
       "0                                  {'Z', 'O', 'OIL'}      1438             1   \n",
       "1  {'ESN', 'RNP', 'G', 'E', 'U', 'PCO', 'PCU', 'M...      4413             1   \n",
       "2  {'M', 'RNP', 'D', 'PTD', 'E', 'U', 'T', 'PMF',...      2108             2   \n",
       "3  {'M', 'RNP', 'D', 'PTD', 'E', 'U', 'T', 'PMF',...      1776             6   \n",
       "4  {'M', 'RNP', 'D', 'PTD', 'E', 'U', 'T', 'PMF',...      1776             6   \n",
       "\n",
       "    headlineTag  marketCommentary  sentenceCount  wordCount  \\\n",
       "0           NaN             False             11        275   \n",
       "1       FEATURE             False             55        907   \n",
       "2  PRESS DIGEST             False             15        388   \n",
       "3  PRESS DIGEST             False             14        325   \n",
       "4  PRESS DIGEST             False             14        325   \n",
       "\n",
       "                                  assetCodes                        assetName  \\\n",
       "0  {'0857.HK', 'PTR.N', '0857.F', '0857.DE'}                PetroChina Co Ltd   \n",
       "1                                  {'STA.N'}          Travelers Companies Inc   \n",
       "2                        {'WMT.N', 'WMT.DE'}              Wal-Mart Stores Inc   \n",
       "3          {'GOOG.O', 'GOOG.OQ', 'GOOGa.DE'}                       Google Inc   \n",
       "4                                 {'XMSR.O'}  XM Satellite Radio Holdings Inc   \n",
       "\n",
       "   firstMentionSentence  relevance  sentimentClass  sentimentNegative  \\\n",
       "0                     6   0.235702              -1           0.500739   \n",
       "1                     8   0.447214              -1           0.600082   \n",
       "2                    14   0.377964              -1           0.450049   \n",
       "3                    13   0.149071              -1           0.752917   \n",
       "4                    11   0.149071              -1           0.699274   \n",
       "\n",
       "   sentimentNeutral  sentimentPositive  sentimentWordCount  noveltyCount12H  \\\n",
       "0          0.419327           0.079934                  73                0   \n",
       "1          0.345853           0.054064                  62                1   \n",
       "2          0.295671           0.254280                  67                0   \n",
       "3          0.162715           0.084368                  83                0   \n",
       "4          0.209360           0.091367                 102                0   \n",
       "\n",
       "   noveltyCount24H  noveltyCount3D  noveltyCount5D  noveltyCount7D  \\\n",
       "0                0               0               0               0   \n",
       "1                1               1               1               1   \n",
       "2                0               0               0               0   \n",
       "3                0               0               0               0   \n",
       "4                0               0               0               0   \n",
       "\n",
       "   volumeCounts12H  volumeCounts24H  volumeCounts3D  volumeCounts5D  \\\n",
       "0                0                0               3               6   \n",
       "1                1                1               3               3   \n",
       "2                0                0               5              11   \n",
       "3                0                0               5              13   \n",
       "4                0                0               0               0   \n",
       "\n",
       "   volumeCounts7D  \n",
       "0               7  \n",
       "1               3  \n",
       "2              17  \n",
       "3              15  \n",
       "4               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess and Merge the Two Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessAndMerge():\n",
    "    \"\"\"\n",
    "    Preprocess market_data and news_data, merge the two datasets and save to out_filepath\n",
    "    \"\"\"\n",
    "    def __init__(self, market_df, news_df, out_filepath):\n",
    "        \"\"\" Pass inputs to class variables\n",
    "        \"\"\"\n",
    "        self.market_data = market_df\n",
    "        self.news_data = news_df\n",
    "        self.out_filepath = out_filepath\n",
    "\n",
    "    def find_asset_name_map(self, market_data, news_data):\n",
    "        \"\"\" Find assetName correspondences between market_data and news_data\n",
    "        \"\"\"\n",
    "        # Get assetCode and assetName for both market_data and news_data\n",
    "        code_name_market = market_data[['assetCode', 'assetName']].drop_duplicates(subset=['assetCode'])\n",
    "        code_name_news = news_data[['assetCodes', 'assetName']].drop_duplicates(subset=['assetCodes', 'assetName'])\n",
    "        # Split \"assetCodes\" from news_data\n",
    "        code_name_news['assetCodes'] = code_name_news['assetCodes'].str.strip('{}').str.split(',')\n",
    "        # For each assetCode in the list of \"assetCodes\", prepare a new row for each assetcode\n",
    "        assetCode = code_name_news.apply(lambda x: pd.Series(x['assetCodes']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "        assetCode.name = 'assetCode'\n",
    "        code_name_news.drop('assetCodes', axis=1, inplace=True)\n",
    "        code_name_news_joined = code_name_news.join(assetCode).reset_index(drop=True)\n",
    "        code_name_news_joined['assetCode'] = code_name_news_joined['assetCode'].apply(lambda x: x.replace(\"'\",\"\"))\n",
    "        code_name_news_joined['assetCode'] = code_name_news_joined['assetCode'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "        # Rename assetName to assetName_news\n",
    "        code_name_news_joined.rename(columns={'assetName': 'assetName_news'}, inplace=True)\n",
    "        # Merge two dataframes together\n",
    "        code_name_merged = pd.merge(left=code_name_market, right=code_name_news_joined, how='left', on=['assetCode'])\n",
    "        # Filter out Unknown and NAN assetName\n",
    "        code_name_merged.dropna(inplace=True)\n",
    "        condition = code_name_merged['assetName'] == 'Unknown'\n",
    "        code_name_filtered = code_name_merged[~condition]\n",
    "        # Build up a dictionary to establish assetName mapping from news_data to market_data\n",
    "        assetName_map = {}\n",
    "        for index, row in code_name_filtered.iterrows():\n",
    "            if row['assetName'] != row['assetName_news']:\n",
    "                assetName_map[row['assetName_news']] = row['assetName']\n",
    "        return assetName_map\n",
    "\n",
    "    def merge_by_asset_name(self, market_data, news_data, assetName_map):\n",
    "        \"\"\" Merge market_data and news_data, according to assetName\n",
    "        \"\"\"\n",
    "        # Modify assetName in news_data according to assetName_map, so that it becomes the same as assetName in market_data\n",
    "        news_data['assetName'] = news_data['assetName'].apply(lambda x: assetName_map[x] if x in assetName_map.keys() else x)\n",
    "        news_data.drop(['assetCodes'], axis=1, inplace=True)\n",
    "        # Integrate multiple news articles for a stock for a day into one aggregated row\n",
    "        news_data_grouped = news_data.groupby(['time','assetName'], sort=False).aggregate(np.mean).reset_index()  \n",
    "        news_data_grouped_max = news_data.groupby(['time','assetName'], sort=False).aggregate(np.max).reset_index()\n",
    "        dummies = [column for column in news_data.columns if 'dummy_' in column]\n",
    "        news_data_grouped[dummies] = news_data_grouped_max[dummies]\n",
    "        del news_data, news_data_grouped_max\n",
    "        # Merge two DataFrames\n",
    "        return pd.merge(left=market_data, right= news_data_grouped, how='left', on=['time', 'assetName'], copy=False)\n",
    "    \n",
    "    def preprocess_and_merge(self):\n",
    "        \"\"\" Preprocess market_data and news_data, and save the merged dataset\n",
    "        \"\"\"\n",
    "        ### Initialization\n",
    "        market_data = self.market_data\n",
    "        news_data = self.news_data\n",
    "        \n",
    "        ### Preprocess news features\n",
    "        # Convert subjects from texts to numeric dummies\n",
    "        selected_subjects = ['ENER', 'BMAT', 'INDS', 'CYCS', 'NCYC', 'SHOP', 'FDRT', 'HECA', 'FINS', 'TECH', 'TCOM', 'MDIA', \n",
    "                             'UTIL', 'REAL', 'RES', 'RESF', 'RCH', 'DIV', 'IPO', 'MRG', 'DEAL1', 'BKRT', 'CEO1', 'LAYOFS',\n",
    "                             'ACB', 'CLJ', 'BRIB', 'HACK', 'FAKE1', 'SCAM1', 'EMRG', 'US', 'WEU', 'ASIA', 'CN', 'STX', 'DBT',\n",
    "                             'CDM', 'COM', 'DRV', 'FRX', 'GVD', 'HOT', 'MTG', 'PVE', 'MUNI', 'HEDGE']\n",
    "        news_data['subjects'] = news_data['subjects'].apply(lambda x: \n",
    "                                                          [sub for sub in list(eval(x)) if sub in selected_subjects])\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        dummy_subjects = pd.DataFrame(mlb.fit_transform(news_data['subjects']),\n",
    "                                      columns=['dummy_' + name for name in mlb.classes_], index=news_data.index)\n",
    "        selected_subjects = ['dummy_' + name for name in selected_subjects]\n",
    "        news_data = pd.concat([news_data, dummy_subjects[selected_subjects]], axis = 1)\n",
    "        del dummy_subjects\n",
    "        print('Creating news data dummies: done!')\n",
    "        # Drop some columns in news data (the list of dropped columns can be modified)\n",
    "        drop_list = ['sourceTimestamp','firstCreated','sourceId','headline','urgency',\n",
    "                     'provider','subjects','audiences','headlineTag','marketCommentary']\n",
    "        news_data.drop(drop_list, axis=1, inplace=True)\n",
    "        print('Drop columns for news data: done!')\n",
    "\n",
    "        ### Preprocess market_data time\n",
    "        market_data['time'] = pd.to_datetime(market_data['time']).apply(lambda x: x.date())\n",
    "        print('Preprocessing market data time: done!')   \n",
    "\n",
    "        ### Preprocess news_data time\n",
    "        nytimezone = timezone(\"US/Eastern\")\n",
    "        # Convert from UTC to New York timezone\n",
    "        news_data['time'] = pd.to_datetime(news_data['time']).apply(lambda x: x.tz_localize(UTC).astimezone(nytimezone))\n",
    "        # Transform timestamp between time [9:30 am, date t ~ 9:30 am date t+1] to date t\n",
    "        market_open = dt.time(9, 30, 0)\n",
    "        news_data['time'] = news_data['time'].apply(lambda x: x.date() \n",
    "                                                    if x.time() >= market_open else x.date() - dt.timedelta(days = 1)) \n",
    "        ## Adjust 'time' for news_data: replace non-trading dates with last trading date (e.g. Sat/Sun to Fri)\n",
    "        # First, get all the unique dates from news_data and market_data\n",
    "        time_market = pd.DataFrame(market_data['time'].unique(), columns={'time'})\n",
    "        time_news = pd.DataFrame(news_data['time'].unique(), columns={'time'})\n",
    "        # Keep a copy of market_date before merging\n",
    "        time_market['time_market'] = time_market['time']\n",
    "        # Merge the two dataframes, the merged dataframe should have the same length with time_news\n",
    "        # Also fill with the last trading date\n",
    "        time_adjusted= pd.merge(left=time_market, right= time_news, how='right', on=['time'], sort=True).fillna(method='ffill')\n",
    "        # Merge adjusted time to news_data\n",
    "        news_data_adjusted = pd.merge(left=news_data, right=time_adjusted, how='left', on=['time'], copy=False)\n",
    "        del news_data\n",
    "        # Modify 'time_market' as the new 'time' column\n",
    "        news_data_adjusted.drop(['time'], axis=1, inplace=True)\n",
    "        news_data_adjusted.rename(columns={'time_market': 'time'}, inplace=True)\n",
    "        print('Preprocessing news data time: done!')\n",
    "\n",
    "        ### Find assetName map from market_data to news_data\n",
    "        assetName_map = self.find_asset_name_map(market_data, news_data_adjusted)\n",
    "        print('Find the assetName correspondences between market and news data: done!')\n",
    "\n",
    "        ### Merge market and news data\n",
    "        merged_data = self.merge_by_asset_name(market_data, news_data_adjusted, assetName_map)\n",
    "        print('Merging market and news: done!')\n",
    "        \n",
    "        ### Save merged data\n",
    "        merged_data.to_csv(self.out_filepath)\n",
    "        print(\"Saving merged data: done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Call Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating news data dummies: done!\n",
      "Drop columns for news data: done!\n",
      "Preprocessing market data time: done!\n",
      "Preprocessing news data time: done!\n",
      "Find the assetName correspondences between market and news data: done!\n",
      "Merging market and news: done!\n",
      "Saving merged data: done!\n",
      "Running time -- 0:29:53.267146\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "out_filepath = \"../Data/merged_data.csv\"\n",
    "a = PreprocessAndMerge(market_df, news_df, out_filepath)\n",
    "a.preprocess_and_merge()\n",
    "print(\"Running time -- {0}\".format(dt.timedelta(seconds = time.time() - start_time ) ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
